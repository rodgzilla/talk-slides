\documentclass[9pt]{beamer}

\input{packages.tex}
\input{colors.tex}

\usetheme{Boadilla}
\title{Deep learning basics}
\author{G. Châtel}
\date{June 4th, 2018}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \maketitle

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Machine learning}

  \framesubtitle{Supervised learning}

  Machine learning is a subfield of artificial intelligence.

  \bigskip

  \begin{description}
    \item[Intuitively] We want to \emph{learn from} and \emph{make predictions
    on} data.

    \medskip

    \item[Technically] We want to build a model that approximate well
      (\textit{e.g.} minimize a loss function) an unknown function.
  \end{description}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Application examples}

  \framesubtitle{Supervised learning}

  \begin{itemize}
    \item Regression

      \smallskip

      \begin{center}
        \begin{tabular}{cc}
          \textcolor{blue}{Polynomial} & $(x, y, z) \to f(x, y, z)$ \\[0.5cm]
          \textcolor{blue}{House price} & (surface, nb rooms, city) $\to$ price \\[0.5cm]
        \end{tabular}
      \end{center}

    \item Classification

      \smallskip

      \begin{center}
        \begin{tabular}{cc}
          \textcolor{blue}{Image classification} & pixel values $\to$ cat or dog \\[0.5cm]
          \textcolor{blue}{Text classification} & list of words $\to$ spam or valid email
        \end{tabular}
      \end{center}
  \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Deep learning}

  \textcolor{blue}{Deep learning} is a subfield of machine learning in
  which we use \textcolor{blue}{artificial neural networks} to make
  predictions.

  \bigskip

  An artificial neural networks is a computation model \emph{loosely}
  based on the human brain. It aims to mimic electric signals
  travelling through neurons in order to make computations.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Artificial neural network}

  \framesubtitle{Neuron}

  \begin{center}
    \scalebox{0.6}{
      \input{figures/nonlinear_neuron.tex}
    }
  \end{center}

  \uncover<1->{
    \[
    A(x) = \begin{cases}
        0 & \text{if } x < 0 \\
        1 & \text{otherwise}
    \end{cases}
    \]
  }

  \uncover<2->{
    \[
    y = A(w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + w_{4}x_{4} + w_{5}x_{5} + w_{6}x_{6} + b)
    \]
  }
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Artificial neural network}

  \framesubtitle{Network}

  \begin{center}
    \scalebox{0.7}{
      \input{figures/network.tex}
    }
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{``Problem'' with this definition}

%%   We now have a quite complicated framework to compute
%%   \textcolor{blue}{linear functions}.

%%   \bigskip

%%   \begin{center}
%%     \begin{tabular}{cc}
%%       \textcolor{blue}{Neuron} & linear function \\
%%       \textcolor{blue}{Neural network} & linear combination of neuron outputs \\
%%     \end{tabular}
%%   \end{center}

%%   \bigskip

%%   To approximate non linear functions, we would like to have a non
%%   linear model.

%%   \bigskip

%%   \uncover<2->{\textcolor{blue}{Solution}: add nonlinearity to neurons.}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Neuron with activation}

%%   \begin{center}
%%     \scalebox{0.6}{
%%       \input{figures/nonlinear_neuron.tex}
%%     }
%%   \end{center}

%%   \uncover<2->{
%%     \[
%%     A(x) = \begin{cases}
%%         0 & \text{if } x < 0 \\
%%         1 & \text{otherwise}
%%     \end{cases}
%%     \]
%%   }

%%   \uncover<3->{
%%     \[
%%     y = A(w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + w_{4}x_{4} + w_{5}x_{5} + w_{6}x_{6} + b)
%%     \]
%%   }
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Computation example}

  \framesubtitle{Binary AND gate}

  \begin{center}
    \scalebox{1}{
      \input{figures/and_neuron.tex}
    }
  \end{center}

  We want to set $w_{1}, w_{2}$ and $b$ such that:

  \[
  A(w_{1}x_{1} + w_{2}x_{2} + b) = x_{1} \text{ AND } x_{2}
  \]

  \uncover<3->{
    \[
    x_{0} = 0, x_{1} = 1. \quad y = A(0 + 1 - 1.5) = A(-0.5) = 0
    \]
  }

  \uncover<4->{
    \[
    x_{0} = 1, x_{1} = 1. \quad y = A(1 + 1 - 1.5) = A(0.5) = 1
    \]
  }
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Computation example}

%%   \framesubtitle{Binary XOR gate}

%%   \begin{center}
%%     \scalebox{0.7}{
%%       \input{figures/xor_neuron.tex}
%%     }
%%   \end{center}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Model complexity}

  One way to measure the complexity of a neural network is its number
  of parameters.

  \bigskip

  \begin{itemize}
    \uncover<2->{
    \item AND network: 3 parameters
    }
    \bigskip
    \uncover<3->{
    \item dogs vs cats pictures (VGG16 network): 138,357,544 parameters
    }
  \end{itemize}

  %% \bigskip
  %% \uncover<4->{We should probably look for a way to tune these
  %%   parameters automatically otherwise it is going to get
  %%   \emph{really} boring \emph{really} quickly.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Parameter tuning}

%%   \framesubtitle{Line approximation}

%%   We have a few sample points and we want to find a line that
%%   approximate these points.

%%   \begin{center}
%%     \scalebox{0.8}{
%%       \input{figures/scatter_01.tex}
%%     }
%%   \end{center}

%%   Our model is just a line

%%   \[
%%   y_{pred} = \textcolor{red}{a}x + \textcolor{red}{b}
%%   \]

%%   \bigskip

%%   We want to find $a$ and $b$ to best match our samples.

%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Parameter tuning}

%%   \framesubtitle{Gradient descent}

%%   First we have a define a \textcolor{blue}{loss} that measures how
%%   good our predictions are.

%%   \[
%%   l(x, y, a, b) = (y - y_{pred})^{2} = (y - (a x + b))^{2}
%%   \]

%%   \bigskip

%%   and now, we compute how the loss is affected by small changes of $a$ and
%%   $b$:

%%   \medskip

%%   \[
%%   \frac{dl}{da} = 2 x (ax + b - y) \qquad \qquad \frac{dl}{db} = 2 (ax + b - y)
%%   \]
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Parameter tuning}

%%   \framesubtitle{Gradient descent}

%%   We start with random values: $a = -2$ and $b = 1$

%%   \begin{center}
%%     \scalebox{0.7}{
%%       \input{figures/scatter_02.tex}
%%     }
%%   \end{center}

%%   Then, we compute the average of the gradient along all $(x, y)$ couples

%%   \begin{overprint}
%%     \onslide<1> \[ a = -2.00 \quad b = 1.00 \quad \overline{\frac{dl}{da}} = -1.07 \quad \overline{\frac{dl}{db}} = -1.37 \quad \overline{l(x, y, a, b)} = 0.860367 \]
%%     \onslide<2> \[ a = -1.18 \quad b = 1.30 \quad \overline{\frac{dl}{da}} = -0.17 \quad \overline{\frac{dl}{db}} = 0.09 \quad \overline{l(x, y, a, b)} = 0.159420 \]
%%     \onslide<3> \[ a = -0.82 \quad b = 1.10 \quad \overline{\frac{dl}{da}} = -0.13 \quad \overline{\frac{dl}{db}} = 0.07 \quad \overline{l(x, y, a, b)} = 0.088204 \]
%%     \onslide<4> \[ a = -0.54 \quad b = 0.94 \quad \overline{\frac{dl}{da}} = -0.09 \quad \overline{\frac{dl}{db}} = 0.05 \quad \overline{l(x, y, a, b)} = 0.048802 \]
%%     \onslide<5> \[ a = -0.34 \quad b = 0.83 \quad \overline{\frac{dl}{da}} = -0.07 \quad \overline{\frac{dl}{db}} = 0.04 \quad \overline{l(x, y, a, b)} = 0.027001 \]
%%     \onslide<6> \[ a = -0.19 \quad b = 0.75 \quad \overline{\frac{dl}{da}} = -0.05 \quad \overline{\frac{dl}{db}} = 0.03 \quad \overline{l(x, y, a, b)} = 0.014939 \]
%%     \onslide<7> \[ a = -0.08 \quad b = 0.68 \quad \overline{\frac{dl}{da}} = -0.04 \quad \overline{\frac{dl}{db}} = 0.02 \quad \overline{l(x, y, a, b)} = 0.008266 \]
%%     \onslide<8> \[ a = 0.01 \quad b = 0.64 \quad \overline{\frac{dl}{da}} = -0.03 \quad \overline{\frac{dl}{db}} = 0.02 \quad \overline{l(x, y, a, b)} = 0.004573 \]
%%     \onslide<9> \[ a = 0.07 \quad b = 0.60 \quad \overline{\frac{dl}{da}} = -0.02 \quad \overline{\frac{dl}{db}} = 0.01 \quad \overline{l(x, y, a, b)} = 0.002530 \]
%%     \onslide<10> \[ a = 0.12 \quad b = 0.58 \quad \overline{\frac{dl}{da}} = -0.02 \quad \overline{\frac{dl}{db}} = 0.01 \quad \overline{l(x, y, a, b)} = 0.001400 \]
%%     \onslide<11> \[ a = 0.15 \quad b = 0.56 \quad \overline{\frac{dl}{da}} = -0.01 \quad \overline{\frac{dl}{db}} = 0.01 \quad \overline{l(x, y, a, b)} = 0.000775 \]
%%     \onslide<12> \[ a = 0.18 \quad b = 0.54 \quad \overline{\frac{dl}{da}} = -0.01 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000429 \]
%%     \onslide<13> \[ a = 0.19 \quad b = 0.53 \quad \overline{\frac{dl}{da}} = -0.01 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000237 \]
%%     \onslide<14> \[ a = 0.21 \quad b = 0.52 \quad \overline{\frac{dl}{da}} = 0.00 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000131 \]
%%     \onslide<15> \[ a = 0.22 \quad b = 0.52 \quad \overline{\frac{dl}{da}} = 0.00 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000073 \]
%%     \onslide<16> \[ a = 0.23 \quad b = 0.51 \quad \overline{\frac{dl}{da}} = 0.00 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000040 \]
%%     \onslide<17> \[ a = 0.23 \quad b = 0.51 \quad \overline{\frac{dl}{da}} = 0.00 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000022 \]
%%     \onslide<18> \[ a = 0.24 \quad b = 0.51 \quad \overline{\frac{dl}{da}} = 0.00 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000012 \]
%%     \onslide<19> \[ a = 0.24 \quad b = 0.51 \quad \overline{\frac{dl}{da}} = 0.00 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000007 \]
%%     \onslide<20> \[ a = 0.24 \quad b = 0.50 \quad \overline{\frac{dl}{da}} = 0.00 \quad \overline{\frac{dl}{db}} = 0.00 \quad \overline{l(x, y, a, b)} = 0.000004 \]
%%   \end{overprint}

%%   \bigskip

%%   And update $a$ and $b$ by substracting a small proportion of their
%%   gradient.

%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}

%%   \frametitle{Parameter tuning}

%%   \framesubtitle{Problem with ANN}

%%   Using gradient descent, we know how to minimize (or at least reach a
%%   local minima) a differentiable function.

%%   \pause
%%   \bigskip

%%   \textcolor{red}{Problem}: The function computed by our neural network is not
%%   differentiable because of the activation function.

%%   \[
%%   A(x) = \begin{cases}
%%     0 & \text{if } x < 0 \\
%%     1 & \text{otherwise}
%%   \end{cases}
%%   \]

%%   \medskip

%%   \pause

%%   \textcolor{blue}{Solution}: We replace it by a differentiable
%%   function that does the same job.

%%   \begin{center}
%%     \begin{tikzpicture}[xscale = 4]
%%       \node (formula) (0, 0){
%%         \scalebox{1.3}{
%%           $A(x) = \frac{1}{1 + e^{-x}}$
%%         }
%%       } ;

%%       \node (graph) at (1, 0){
%%         \scalebox{0.6}{
%%           \input{figures/sigmoid.tex}
%%         }
%%       };
%%     \end{tikzpicture}
%%   \end{center}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Convolution}

%%   \framesubtitle{Motivation}

%%   For now, our networks computes a nonlinear function of the
%%   inputs. If we work with images, it has to learn the \emph{spacial
%%     structure} of the data by itself, which takes a long time.

%%   \bigskip

%%   A nice way to help it is to build \textcolor{blue}{convolution
%%     layers} into the network.
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}

%%   \frametitle{Convolution}

%%   \framesubtitle{Kernel}

%%   \begin{center}
%%     \scalebox{0.55}{
%%       \includegraphics{images/kernel.jpg}
%%     }
%%   \end{center}

%%   {\small Image from \url{http://stats.stackexchange.com/}}

%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}

%%   \frametitle{Convolution}

%%   \framesubtitle{Example: Sobel operators}

%%   \begin{center}
%%     \scalebox{0.9}{
%%       \input{figures/convolutions_examples.tex}
%%     }
%%   \end{center}

%%   {\small Image from \url{http://www.reddit.com/}}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Convolutional neural network}

  \framesubtitle{VGG network (2014)}

  \begin{center}
    \scalebox{0.5}{
      \includegraphics{images/vgg16_architecture.png}
    }
  \end{center}

  Classify natural images into 1000 categories. (92.7\% top-5
  accuracy).

  \medskip

  {\footnotesize Image from
    \url{https://www.cs.toronto.edu/~frossard/post/vgg16/}}

  \smallskip

  {\footnotesize Simonyan, K., \& Zisserman, A. (2014). Very deep
    convolutional networks for large-scale image recognition. arXiv
    preprint arXiv:1409.1556.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Convolution}

%%   \framesubtitle{What do filter recognize?}

%%   {\small Image from \url{http://www.matthewzeiler.com/pubs/arxive2013/eccv2014.pdf}}

%%   \begin{center}
%%     \begin{overprint}
%%       \onslide<1> \includegraphics[width = 4cm]{images/cnn_vizu_l1.jpg}
%%       \onslide<2> \includegraphics[width = 11cm]{images/cnn_vizu_l2.jpg}
%%       \onslide<3> \includegraphics[width = 11cm]{images/cnn_vizu_l3.jpg}
%%       \onslide<4> \includegraphics[width = 9cm]{images/cnn_vizu_l4.jpg}
%%       \onslide<5> \includegraphics[width = 9cm]{images/cnn_vizu_l5.jpg}
%%     \end{overprint}
%%   \end{center}

%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}

%%   \frametitle{Convolutional neural network}

%%   \framesubtitle{VGG network (2014)}

%%   \begin{center}
%%     \scalebox{0.6}{
%%       \includegraphics{images/vgg16_architecture.png}
%%     }
%%   \end{center}

%%   {\small Image from \url{https://www.cs.toronto.edu/~frossard/post/vgg16/}}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Deep autoencoder}

  \begin{center}
    \scalebox{0.6}{
      \includegraphics{images/autoencoder.png}
    }
  \end{center}

  \medskip

  If we cut this autoencoder at the bottleneck, we get two parts: an
  encoder and a decoder. The encoder is an encoder highly specific to
  the content the network has been trained with.

  \bigskip

  {\footnotesize Hinton, G. E., \& Salakhutdinov,
    R. R. (2006). Reducing the dimensionality of data with neural
    networks. science, 313(5786), 504-507.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Deep autoencoder: Compression}

  \begin{center}
    \scalebox{0.3}{
      \includegraphics{images/generative_compression.png}
    }
  \end{center}

  \medskip

  If we force the output image to be realistic, we lose
  \emph{semantic information} rather than resolution.

  \bigskip

  {\footnotesize Santurkar, S., Budden, D., \& Shavit,
    N. (2017). Generative compression. arXiv preprint
    arXiv:1703.01467.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Drawing cleanup}

  \begin{center}
    \includegraphics[width = \linewidth]{images/drawing_simplification_example.png}
  \end{center}

  \bigskip

  {\footnotesize Simo-Serra, E., Iizuka, S., Sasaki, K., \& Ishikawa,
    H. (2016). Learning to simplify: fully convolutional networks for
    rough sketch cleanup. ACM Transactions on Graphics (TOG), 35(4),
    121.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Architecture examples}

%%   \framesubtitle{CNN + Autoencoder network: drawing simplification}

%%   \begin{center}
%%     \includegraphics[width=\linewidth]{images/drawing_simplification.png}
%%   \end{center}

%%   Simo-Serra, Iizuka, Sasaki, Ishikawa (2016)
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Architecture examples}

%%   \framesubtitle{Neural style}

%%   Consider an image $I$ and its image by the convolution layers of the
%%   VGG network $Conv(I)$.

%%   \pause
%%   \bigskip

%%   We can reconstruct a picture $I'$ with the same content as $I$ by
%%   applying gradient descent on the pixels in order to obtain $Conv(I)$
%%   as output, starting with white noise.

%%   \begin{center}
%%     \scalebox{0.6}{
%%       \input{figures/nonlinear_neuron_animation.tex}
%%     }
%%   \end{center}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Architecture examples}

%%   \framesubtitle{Neural style}

%%   Gatys, Ecker and Bethge built a formula to extract the
%%   \textit{style} of an image using the convolutional layers of the VGG
%%   network (2015).

%%   \bigskip

%%   They build the following Gram matrix:

%%   \bigskip

%%   \[
%%   G_{ij}^{l} = \sum_{k} F_{ik}^{l} F_{jk}^{l}
%%   \]

%%   \bigskip

%%   where $F_{ij}^{l}$ is the $j$-th output of the $i$-th filter of the
%%   $l$-th convolutional layer.

%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Neural style transfer}

  Let's take a random image from the internet.

  \begin{center}
    \scalebox{0.1}{
      \includegraphics{images/greg_face.jpg}
    }
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Neural style transfer}

  \begin{center}
    \begin{tikzpicture}
      \node (coefface) at (-1.7, 0) {
        $\alpha$ content(
      };

      \node (face) at (0.1, 0) {
        \includegraphics[width = 2cm]{images/greg_face.jpg}
      };

      \node (plus) at (2, 0) {
        $)+ \beta$ style(
      };

      \node (vangogh) at (4.3, 0) {
        \includegraphics[width = 2.5cm]{images/van_gogh.jpg}
      };

      \node (eq) at (6, 0){
        $) =$
      };

      \node (result) at (7.5, 0){
        \scalebox{0.15}{
          \includegraphics{images/face_vg.jpg}
        }
      };
    \end{tikzpicture}
  \end{center}

  \bigskip

  {\footnotesize Image created using \url{https://deepart.io}}

  \medskip

  {\footnotesize Gatys, L. A., Ecker, A. S., \& Bethge, M. (2015). A
    neural algorithm of artistic style. arXiv preprint
    arXiv:1508.06576.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Neural style transfer}

  \begin{center}
    \begin{tikzpicture}
      \node (coefface) at (-1.7, 0) {
        $\alpha$ content(
      };

      \node (face) at (0.1, 0) {
        \includegraphics[width = 2cm]{images/greg_face.jpg}
      };

      \node (plus) at (2, 0) {
        $)+ \beta$ style(
      };

      \node (lines) at (4.3, 0) {
        \includegraphics[width = 2.5cm]{images/lines.jpg}
      };

      \node (eq) at (6, 0){
        $) =$
      };

      \node (result) at (7.5, 0){
        \scalebox{0.15}{
          \includegraphics{images/face_ln.jpg}
        }
      };
    \end{tikzpicture}
  \end{center}

  \bigskip

  {\footnotesize Image created using \url{https://deepart.io}}

  \medskip

  {\footnotesize Gatys, L. A., Ecker, A. S., \& Bethge, M. (2015). A
    neural algorithm of artistic style. arXiv preprint
    arXiv:1508.06576.}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Neural style transfer}

  \begin{center}
    \begin{tikzpicture}
      \node (coefface) at (-1.7, 0) {
        $\alpha$ content(
      };

      \node (face) at (0.1, 0) {
        \includegraphics[width = 2cm]{images/greg_face.jpg}
      };

      \node (plus) at (2, 0) {
        $)+ \beta$ style(
      };

      \node (vangogh) at (4.3, 0) {
        \includegraphics[width = 2.5cm]{images/flowers.jpg}
      };

      \node (eq) at (6, 0){
        $) =$
      };

      \node (result) at (7.5, 0){
        \scalebox{0.15}{
          \includegraphics{images/face_fl.jpg}
        }
      };
    \end{tikzpicture}
  \end{center}

  \bigskip

  {\footnotesize Image created using \url{https://deepart.io}}

  \medskip

  {\footnotesize Gatys, L. A., Ecker, A. S., \& Bethge, M. (2015). A
    neural algorithm of artistic style. arXiv preprint
    arXiv:1508.06576.}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Neural style transfer}

  \begin{center}
    \begin{tikzpicture}
      \node (coefface) at (-1.7, 0) {
        $\alpha$ content(
      };

      \node (face) at (0.1, 0) {
        %% \includegraphics[width = 2cm]{images/van_gogh.jpg}
        \includegraphics[width = 2cm]{images/grant.jpg}
      };

      \node (plus) at (2, 0) {
        $)+ \beta$ style(
      };

      \node (vangogh) at (4.3, 0) {
        \includegraphics[width = 2.5cm]{images/greg_face}
      };

      \node (eq) at (6, 0){
        $) =$
      };

      \node (result) at (7.5, 0){
        \scalebox{0.15}{
          \includegraphics{images/grant_transfer.jpg}
        }
      };
    \end{tikzpicture}
  \end{center}

  \bigskip

  {\footnotesize Image created using \url{https://deepart.io}}

  \medskip

  {\footnotesize Gatys, L. A., Ecker, A. S., \& Bethge, M. (2015). A
    neural algorithm of artistic style. arXiv preprint
    arXiv:1508.06576.}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Architecture examples}

%%   \framesubtitle{Recurrent neural network}

%%   \begin{center}
%%     \scalebox{0.4}{
%%       \includegraphics{images/rnn.jpg}
%%     }
%%   \end{center}

%%   {\small Image from \url{http://www.wildml.com}}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Reinforcement learning}

  \framesubtitle{DeepMind's AlphaGo}

  \begin{center}
    \includegraphics[width=0.65\linewidth]{images/alphago.jpg}
  \end{center}

  \medskip

  In 2016, DeepMind showcased an artificial intelligence for the game
  of Go that managed to beat Lee Sedol, one of the strongest player in
  the world.

  \bigskip

  {\footnotesize Silver, D., Huang, A., Maddison, C. J., Guez, A.,
    Sifre, L., Van Den Driessche, G., ... \& Dieleman,
    S. (2016). Mastering the game of Go with deep neural networks and
    tree search. nature, 529(7587), 484-489.}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Architecture examples}

%%   \framesubtitle{Sequence to class network: text classifier}

%%   \begin{center}
%%     \scalebox{0.5}{
%%       \includegraphics{images/text_classification.png}
%%     }
%%   \end{center}

%%   {\small Image from Martin Gorner}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Sequence to sequence network: Neural Machine Translation}

  \begin{center}
    \scalebox{0.25}{
      \includegraphics{images/rnn_translation.png}
    }
  \end{center}

  {\small Image from \url{https://colah.github.io}}

  \bigskip

  Google, September 2016: ``The Google Translate mobile and web apps
  are now using GNMT (Google NMT) for 100\% of machine translations
  from Chinese to English—about 18 million translations per day.''

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Architecture examples}

%%   \framesubtitle{Sequence to sequence network: Neural Conversation Model}

%%   \begin{center}
%%     \scalebox{0.5}{
%%       \includegraphics{images/rnn_response.png}
%%     }
%%   \end{center}

%%   {\small Image from \url{https://github.com/farizrahman4u/seq2seq}}

%%   \bigskip

%%   Really early stage, hard to overcome challenges (context, coherent
%%   personality, \dots)
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Generative adversarial network}

  \begin{center}
    \includegraphics[width=\linewidth]{images/GAN_1.jpg}
  \end{center}

  {\small Image from \url{http://wiki.tum.de/}}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Generative adversarial network: Celebrity faces generation}

  \begin{center}
    \includegraphics[width=0.7\linewidth]{images/progan.png}
  \end{center}

  \bigskip

  {\footnotesize Karras, T., Aila, T., Laine, S., \& Lehtinen,
    J. (2017). Progressive growing of gans for improved quality,
    stability, and variation. arXiv preprint arXiv:1710.10196.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Architecture examples}

%%   \framesubtitle{Image to sequence: automatic captioning}

%%   \begin{center}
%%     \scalebox{0.5}{
%%       \includegraphics{images/captioning_detection.png}
%%     }
%%   \end{center}
%%   {\small Image from \url{https://quantumfrontiers.com}}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Image to sequence: automatic captioning}

  \begin{center}
    \scalebox{0.7}{
      \includegraphics{images/captioning.png}
    }
  \end{center}

  {\small Image from \url{http://brain.kaist.ac.kr/}}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Architecture examples}

  \framesubtitle{Generative adversarial network: text to image}

  \begin{center}
    \includegraphics[width=7.5cm]{images/GAN_2.jpg}
  \end{center}

  {\footnotesize Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X.,
    Wang, X., \& Metaxas, D. (2017, October). Stackgan: Text to
    photo-realistic image synthesis with stacked generative
    adversarial networks. In IEEE Int. Conf. Comput. Vision (ICCV)
    (pp. 5907-5915).}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
